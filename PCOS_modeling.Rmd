---
title: "PCOS modeling"
author: "Erick Navarro"
date: "2023-01-25"
output: 
  pdf_document:
    toc: true
    toc_depth: 4
---
# Creating the classificators

This report contains the details of the generation and comparison of several classificators whose aim is to classify people with and without Polycystic ovary syndrome (PCOS). The goal of this project is to develop and validate a model that takes easily collected variables, and test its performance against models that possess variables obtained with increasing invasive proceedures. For a summary of the results and a clearer picture of the project, please read the Final_report.pdf file in this repository. 

## Setup
### Load packages and data 
```{r setup, include=FALSE}
library(tidyverse)
library(glmnet)
library(caret)
library(here)
library(mice)
library(DataExplorer)

#Make the code reproducible
set.seed(504)
#load the data
load(here("data.Rdata"))
# See how the data looks like
glimpse(data)
```

### Data splitting 

After loading the data and packages, we will proceed to split the data into training and validation sets.

```{r}
data = data %>% 
  column_to_rownames("id")

train.index <- caret::createDataPartition(data$pcos, p = .7, list=FALSE)

train <- data[ train.index,]
valid  <- data[-train.index,]


#Check the negative/positive ration in the validation set
table(train$pcos)
table(train$pcos)[1]/ table(train$pcos)[2]

#Check the negative/positive ration in the validation set
table(valid$pcos)
table(valid$pcos)[1]/ table(valid$pcos)[2]

#Check the negative/positive ration in the original data set
table(data$pcos)[1]/ table(data$pcos)[2]

```

### Imputation on training set

Following the data splitting, we will impute missing values. As we observed in the EDA analysis, the proportion of missing data is overall very low, which makes all the variables with misingness suitable for imputation

```{r}
# Explore misingness in training set 
sapply(train, function(x) sum(is.na(x)))
```

For imputation, we will use the [mice R package](https://cran.r-project.org/web/packages/mice/mice.pdf), a widely used software to handle missing data. We will use the default options, which use the most appropuate methodology depending on the class of the data to be imputed, which are the following: "By default, the method uses pmm, predictive mean matching (numeric data) logreg, logistic regression imputation (binary data, factor with 2 levels) polyreg, polytomous regression imputation for un- ordered categorical data (factor > 2 levels) polr, proportional odds model for (ordered, > 2 levels)."

```{r, message=FALSE}
chained_train = mice::mice(train)

#Explore the imputed data and check that the generated value are plausible 
stripplot(chained_train, pulse_rate, pch = 19, xlab = "Imputation number")
stripplot(chained_train, lh, pch = 19, xlab = "Imputation number")
stripplot(chained_train, fsh_lh_ratio, pch = 19, xlab = "Imputation number")
stripplot(chained_train, amh, pch = 19, xlab = "Imputation number")
stripplot(chained_train, vitd3, pch = 19, xlab = "Imputation number")
stripplot(chained_train, fast_food, pch = 19, xlab = "Imputation number")

#It looks fine so we will proceed to extract the imputed data

chained_train = complete(data=chained_train)

sapply(chained_train, function(x) sum(is.na(x)))
```


### Define the models

For the aim of this project, we will develop 4 different models with an increasing number of variables according to its easiness to collect. Then, model 1 will contain only variables that are collected throught the patient history, model 2 will have clinical examination ones added, model 3 blood tests and model 4 all the relevant variables available in the dataset. 

It is worth mentioning that we removed some non-relevant variables from the datset based on the scientific literature of the field. A more detailed information about this selection can be found in the final report available in this repository. 

```{r}
# Create dataset 1 using only variables obtained through through patient history
model1_vars = c("pcos","age","cycle","cycle_length",
                 "no_of_abortions", "weight_gain", "hair_growth", "skin_darkening",
                 "hair_loss","pimples","fast_food", "reg_exercise")

# Create dataset 2 using variables obtained through patient history and clinical examination
model2_vars  = c(model1_vars, "weight","height","bmi",
                 "hip", "waist","waist_hip_ratio",
                 "bp_systolic", "bp_diastolic")

# Create dataset 3 using variables obtained through patient history, clinical examination and blood tests
model3_vars = c(model2_vars, "fsh", "lh", "fsh_lh_ratio",
              "amh", "prl", "vitd3", "prg", "rbs")

# Create dataset 4 using variables obtained through patient history, clinical examination, blood tests and ultrasound
model4_vars = c(model3_vars, "follicle_no_l", "follicle_no_r" ,
              "avg_f_size_l", "avg_f_size_r", "endometrium")
```


### Logistic regression modeling

### Elastic net regression

For the RIDGE regression, I will start by finding the optimal lambda value using the function cv.glmnet(). I will do a 10-fold cross validation process to achieve this. 

```{r}
#convert training data to matrix format
x_matrix <- model.matrix(pcos_y_n~.,train)

#convert class to numerical variable
response <- ifelse(train$pcos_y_n=="1",1,0)

#perform grid search to find optimal value of lambda
ridge.cv <- cv.glmnet(x_matrix,response,alpha=0,
                      nfolds = 10,
                      family="binomial",type.measure = "class" )
#plot result
plot(ridge.cv)
```

After doing this search, I will use the lambda that gives the simplest model but also lies within one standard error of the optimal value of lambda for the rest of my analysis. 

```{r}
#Check the lambda that I will use
ridge.cv$lambda.1se

coef(ridge.cv,s=ridge.cv$lambda.1se)
```


### Random Forest 

## Model comparison 

*Select the best one at the end 

## Effect of class imbalance on the best model (if time allows)
